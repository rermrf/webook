### 服务注册与发现模型

#### IP 直连
最原始的形态，**就是直接使用 IP + 端口来通信。**

这个过程甚至不能称为服务注册与发现，因为没啥注册，也没啥发现。

缺点很明显：IP 是会变的 + 不好维护。

虽然它很原始，但是偶尔也会使用：
- **在开发环境要联调的时候**。例如说你和同事合作完成一个任务，而后你需要调用你同事的接口，这个时候，你直接用同事电脑的 IP 地址调用，同事就可以本地 DEBUG 了。
- **当你 DEBUG 的时候**。某些时候一些 BUG 只会在特定的某些实例上出现，这个时候你可以直接把请求发到这个实例上。


#### 使用域名 + DNS
既然直接使用 IP 不好用，那么另外一个可行的思路就是**使用域名 + DNS**

考虑到解析域名的开销，所以**一般会在客户端这边缓存 解析域名的结果**。

优点：
- 简单好用，不需要额外的组件。

缺点：
- 如果客户端不缓存 DNS 结果，那么每次调用都会多一次调用。
- 如果客户端缓存 DNS 结果，那么就可能无法及时更新本地可用节点列表。


#### 注册中心机制
既然域名解析的问题是不能及时得到通知，**那么能不能让域名服务器主动通知一下节点变化？**

这就是注册中心的原理，基本的思路就是：
- 服务器在启动的时候主动在注册中心注册一下。
- 客户端在第一次发起调用之前先查询注册中心，而后缓存住可用节点。
- 注册中心在服务端节点发生变动的时候，主动通知一下客户端。

这种形态没有显著的缺点。硬要说缺点，**就是注册中心在大规模集群下绒癌称为瓶颈。**


#### 服务自省
这是阿里 Dubbo 提出来的概念。

在原本的注册中心里面，随着集群规模增长和微服务复杂度上升，导致注册中心的数据越来越多，更新越来越频繁，就会导致注册中心本身成为瓶颈。

于是有了服务自省。它可以看做两个简单的过程：
- 保留注册中心，但是**注册中心里面只有最小化的数据。**
- 剩余的**跟服务有关的元数据，通过一个元数据服务来暴露。**

#### 借助网管的服务注册与发现
实际上，这个并不能算是服务注册与发现，只是说在实践中可能遇到，所以在这里描述一下这个模型

事实上当你的请求经过一个微服务网关的时候，**你首先得知道网关在哪里**。这个过程一般是通过域名来达成的，例如 getway.mycompany.com，或者一个特定的配置项里面得知所有的网关节点的地址。

而网关要把请求转发到真实服务端上，**也就是需要知道服务端的地址，因此这也是一个服务注册与发现的过程**，同样可以借助注册中心，或者 DNS。



### 注册中心机制

#### 服务启动过程
简单来说，服务端在启动的时候，**就需要在注册中心注册自身的信息。**

那么问题来了：服务端怎么知道注册中心在哪呢？

答案是：**一般是通过域名 + 端口或者直接指定 IP + 端口来连上注册中心。**

而且，正常来说如果在启动阶段的服务端A无法连上注册中心，那么服务端A会直接失败（也就是退出程序）。

#### 服务注册什么数据？
大致上可以分成两类：
- 定位信息。通俗来说，**就是 IP + 端口**。
- 其他信息。**这部分信息一般和微服务框架的具体功能有关系**，比如在支持分组功能的微服务框架里面，服务端节点就需要在注册信息里面带上自己的分组信息。

其中，最为关键的就是定位信息，因为客户端要利用这个信息来连上服务端A。


#### 服务端和注册中心保持心跳
在注册成功之后，注册中心会和服务端保持心跳。

根据注册中心选型，微服务框架设计，心跳有两种模式：
- **服务端主动**。也就是服务端每隔一段时间就朝着注册中心发一个心跳，注册中心可以答应也可以不答应（正常来说，服务端只要没收到网络错误，就可以认为和注册中心的联系是正常的）。
- **注册中心主动**。也就是注册中心会主动朝着所有注册的服务端节点发送心跳。

如果心跳失败，注册中心会判定服务端节点已经崩溃，那么就会通知客户端不要使用这个节点。


#### 心跳机制
本质上来说，注册中心和服务端的整个机制，可以看做是租约，心跳就是续租。

那么在租约里面讨论的心跳有关的问题，在注册机制这里一样要讨论。
- 心跳间隔多长？
- 如何判定节点连不上？是一次心跳就连不上，还是多次心跳连不上？

正常来说，这些都是跟业务有关的。核心就是：
- **间隔越短，心跳越频繁，压力越大。**
- **次数越少，越快发现服务端节点崩溃，但是难以应对偶发性心跳失败。**
- **次数越多，越慢发现服务端节点崩溃，但是可以避免一些偶发性心跳失败的问题。**


#### 心跳机制的高级做法
还有一些更加高级的机制，但是比较少采用，性价比不高。

- **双向心跳**。也就是服务端会主动发心跳，注册中心也会主动发心跳。
- **单向心跳失败之后，另外一边主动发起心跳**。例如说在正常情况下，都是服务端主动发心跳给注册中心，但是注册中心在一段时间没有收到服务端的心跳之后，会主动发起心跳。


#### 服务下线
很显然，如果服务端要关闭了，就需要通知注册中心，而后注册中心需要通知客户端。
**客户端会把该节点从可用节点列表里面挪走。**


#### 服务优雅下线

但是下线还有一些细节需要思考：服务端A能不能在告诉注册中心自己下线了，立刻就退出？

答案是不能。**因为这个时候服务端 A 上可能还有一些请求正在处理，而网上也还有客户端正在发请求。**

因此实际上，服务端 A 下线的过程更加复杂一点。

##### 服务优雅下线的具体步骤
- **首先通知注册中心**，服务端节点要下线了。
- **而后，服务端节点不再接受新请求**，包括在网络中读了一半的请求，也会在读完之后，直接拒绝。不会交给后端业务代码处理。
- **服务端需要等待正在处理的请求结束**。如果该服务端节点上还有类似于定时任务之类的东西，也要等待运行运行结束。
- **等服务端已经接收的请求处理完毕，服务端就会结束运行。**
- 进一步考虑部分请求运行太长时间，或者定时任务长时间不能结束，所以服务端节点的整个退出过程也会有超时控制，**超过超时时间，就会直接退出。**


#### 客户端
根据微服务框架的设计，客户端发起服务发现有两个时机。
- **客户端启动的时候**。这种设计一般是在客户端从配置文件，或者注册接口，拿到了所有需要使用的微服务。于是可以在初始化的过程中直接执行服务发现，如果服务发现失败则客户端不会启动。
- 客户端启动的时候，并没有去做服务发现。**而是在第一次调用某个服务的时候，执行服务发现**。

同样的，注册中心和客户端之间也要保持心跳，这样可以保证在服务端数据变更的时候，能够连上客户端，并且通知客户端。


### 服务注册与发现的高可用

#### 高可用的关键点
- 服务端崩了怎么办？
- 注册中心崩了怎么办？
- 客户端崩了怎么办？这个是不需要处理的，因为客户端都崩了就没办法发起调用了。

- 注册中心和服务端之间无法通信怎么办？
- 注册中心和客户端之间无法通信怎么办？这种情况，客户端采取“注册中心崩溃”一致行为来容错。
- 客户端和服务端之间无法通信怎么办？基本上也就是 failover 策略。


##### 服务端崩溃
在注册模型里面，正常来说注册中心能够发现服务端崩溃。

但是这需要时间。也就是说，服务端崩溃到注册中心发现、再到注册中心通知客户端，可能存在秒级的延迟。

这个时候，就要求客户端能够正常处理这个情况。

简单来说，**就是客户端发现服务端连不上之后，就要更换一个节点来重试**，这就是failover 策略。


##### 注册中心崩溃怎么办？ --注册中心高可用

那么首先第一个要确保的就是注册中心不能轻易崩溃。
- **启用注册中心的高可用方案**，例如说部署一个集群，多活方案。
- **双注册中心方案**：也就是注册的时候同时注册两个注册中心，在一个注册中心崩溃之后可以使用另外一个注册中心。
- **按照业务拆分多个注册中心**：也就是说一个公司内部不要只使用一个注册中心，最好是不同的业务使用不同的注册中心，核心业务和非核心业务使用不同的注册中心。

##### 注册中心崩溃怎么办？ --客户端怎么办
注册中心崩溃之后，后果之一就是客户端无法获得服务端变动的信息：例如上线或者下线等。

客户端要想容忍这个错误，可以考虑：
- **使用本地缓存的可用节点信息**，缺陷就是可能不准，有可能有些节点已经下线了，有些节点新加进来。
- 客户端使用本地缓存的节点信息之后，如果发起调用的时候发现无法连通，那么**就要把这个节点移出可用列表。**

但是，**如果一个新服务，因为客户端本身没有缓存任何的可用节点信息，那么就没有办法发起调用**，返回特定的错误，让调用者自己去决定怎么处理。

##### 注册中心崩溃怎么办？ --服务端怎么办
注册中心崩溃之后，服务端已经没有办法更新注册信息了。

- **如果是一个新节点，那么注册失败的时候，他应该直接退出服务。**
- 如果是一个老的节点，此时老客户端可能还在使用本地缓存的注册数据，所以**老节点应该继续提供服务**。

##### 注册中心和服务端之间无法通信

注册中心和服务端之间无法通信的情况下，注册中心会判定服务端已经崩溃，但是实际上服务端还活着。
这个时候，**在客户端收到注册中心的错误判定之前，依旧能够调用服务端，并且收到响应。**

客户端不需要做什么，服务端也不需要做什么，注册中心还是不需要做什么。

但是如果服务端发现自己一段时间无法和注册中心保持心跳之后，要告警，并且考虑要不要直接退出。


### 在 gRPC 中使用注册中心

#### gRPC 默认的服务发现方案

在默认情况下，**gRPC用的是域名解析策略。也就是我们传入的服务地址是一个域名+端口的形态。**

显然，如果你直接传入的就是IP地址，那么连域名解析这一步都省略了。

例如：user_svc.mycompany.com:8090 代表了的是用户服务。
gRPC会定时访问域名服务器，更新本地缓存的可用 IP 地址。
在k8s中，推荐使用这种形态。


#### 原理
在gRPC中使用注册中心也很简单，本质上就是提供一个使用注册中心来实现的 Resolve。
Resolver是 gRPC 中的一个核心抽象，**它代表的是对服务的解析，也就是获得服务的定位信息在内的一些元数据。**

本质上，gRPC根本不知道你使用的是不是注册中心，他只是提供了在客户端这边Resolver接口。

#### 以 etcd 为例
etcd直接提供了一个 gRPC的服务注册与发现的 Resolver 实现。
关键点：
- **创建一个 endpoint.Manager。**
- **添加一个 Endpoint。**
- **后续如果注册数据有变动，那么就可以调用 Update 方法。**
- **后续在退出的时候，需要调用一个 Delete 方法，删除这个 Endpoint。**

```go
package integration

type EtcdTestSuite struct {
	suite.Suite
	client *etcdv3.Client
}

func (s *EtcdTestSuite) SetupSuite() {
	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()
	client, err := etcdv3.New(etcdv3.Config{
		Context:   ctx,
		Endpoints: []string{"localhost:12379"},
	})
	require.NoError(s.T(), err)
	s.client = client
}

func (s *EtcdTestSuite) TestServer() {
	// endpoints 是以服务为维度，一个服务一个 Manager
	em, err := endpoints.NewManager(s.client, "service/interactive")
	require.NoError(s.T(), err)
	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()
	// key 是指这个实例的 key
	// 如果有 instance id， 用 instacne id，如果没有，使用本机 IP + 端口
	// 端口一般从配置文件读
	addr := "127.0.0.1:8090"
	key := "service/interactive/" + addr
	err = em.AddEndpoint(ctx, key, endpoints.Endpoint{
		Addr: addr,
	})
	require.NoError(s.T(), err)

	l, err := net.Listen("tcp", addr)
	require.NoError(s.T(), err)
	server := grpc.NewServer()
	intrv1.RegisterInteractiveServiceServer(server, &igrpc.InteractiveServiceServer{})
	err = server.Serve(l)
	s.T().Log(err)
}

func (s *EtcdTestSuite) TestClient() {
	bd, err := resolver.NewBuilder(s.client)
	require.NoError(s.T(), err)
	// URL 的规范 scheme:///xxxx
	cc, err := grpc.NewClient("etcd:///service/interactive",
		grpc.WithResolvers(bd),
		grpc.WithTransportCredentials(insecure.NewCredentials()))
	client := intrv1.NewInteractiveServiceClient(cc)
	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()
	res, err := client.Get(ctx, &intrv1.GetRequest{
		Biz:   "test",
		BizId: 1,
		Uid:   123,
	})
	require.NoError(s.T(), err)
	s.T().Log(res.GetIntr())

}

func TestEtcd(t *testing.T) {
	suite.Run(t, new(EtcdTestSuite))
}

```




#### 在 K8s 中的服务注册与发现
在上面讨论到的 IP直连、域名、注册中心等几种方式，在 K8s 里面都是够用的，但是要注意两个问题：
- **注册的 IP 必须是外部通信 IP**，或者说必须是 K8s 服务之间通信的IP。
- **IP漂移**。IP漂移是指在网络通信过程中，IP地址发生变化的现象。这个在K8s里面很常见，正常K8s在发现一个Pod崩溃之后，重新启动一个Pod，这个Pod的IP就可能是一个新的IP。但是**如果K8s一些和网络有关的配置发生了变化，也可能导致IP发生偏移。**

硬刺在K8s里面，虽然也可以使用注册中心，但是不太推荐。推荐直接使用 DNS 的，也就是用Service的名字来通信。

#### 当我选用一个注册中心，我需要关心什么？
你在代码中接入一个注册中心的时候，关于 SDK（例如说 etcd 的客户端依赖）你要知道：
- 有没有自动续约机制，如果没有，你就需要自己手动续约。
- 续约的间隔多长时间？
- 续约失败了，SDK 有没有处理机制？
- 注册中心和客户端是什么模型，客户端多久能知道服务端的变化？
知道这些你对系统的运行细节会有更加深刻的把握，在遇到跟服务注册与发现有关的问题时也比较容易定位。

  
#### 微服务框架总结
在以gRPC为底层通信机制的微服务框架之上，基本上服务注册与发现都有一些共同点：
- **必然实现了 gRPC 的 Resolver 接口。**
- **必然有一个 register 过程**，也就是在服务端启动的注册数据。
- **必然有一个续约的过程**。要么是自己写续约，要么是依赖于注册中心客户端提供的续约机制。
- 如果微服务框架本身打算支持很多种不同的服务注册与发现的实现，那么**就会有一个类似于 Registry、Discover之类的接口层，用于构建自己微服务框架内部的一致性抽象。**


#### 注册中心选型

##### CAP 理论
分布式CAP理论是分布式系统中的一个重要概念，它指出一个分布式系统不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）这三个基本要求，最多同时满足其中的两项。
- **一致性**：在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性。当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。强调的是你在任何一个节点上读到的数据都是一样的。
- **可用性**：可用性是指系统提供的服务必须一直处于可用的状态，处于用户的每一个操作请求总是能够在有限时间内返回结果。强调的是不管系统内部发生了什么，集群都需要能够对外提供正常服务。
- **分区容错性**：分区容错性是指系统在出现网络分区（网络故障导致不同部分之间的通信中断）时仍能正常工作的能力。强调的是，网络通信被破坏导致系统被分割成多个部分，依然能够对外提供服务。


##### CP 还是 AP
在分布式环境下，大部分时候P（分区容错性）都是必不可少的。

有两个节点 A 和 B，两者之间通过网络来通信。那么在网络通信不通畅的情况下，你只能：
- **放弃让 A 和 B 之间同步数据，那么意味着你舍弃了一致性。**
- **放弃让 A 和 B 对外服务，也就是你放弃了可用性。**

CAP理论一般在设计中间件的时候需要第一时间确认清楚，而对于用户来说，只要考虑清楚自己的业务是侧重一致性还是侧重可用性，就可以做出决策了。

但是也有例外，比如 etcd 严格来说就是 AC 模型，没有选择P。也就是说，如果网络故障导致集群节点之间不能通信，那么 etcd集群就不可用。



##### 注册中心 CAP 选哪个？
面试的标准答案是选 AP + 客户端容错。

但是**我个人的看法是，小规模随便选，大规模选 AP**。

在服务发现与注册这个模型里面，有一个问题就是：
- 如果你认为拿到错误的数据，也好过拿不到数据，那么你就应该选择 AP。
- 如果你认为我一定要拿到正确的注册信息，那么就应该选CP。

而在小规模的集群的时候，可用性问题并不突出。毕竟这个时候你的负载小，流量小，注册中心想要崩溃都很难。


##### ZooKeeper
使用 ZooKeeper 的优缺点都很明显，有点：
- **API简单**
- **成熟度高**
- **支持多语言客户端**：ZooKeeper 出来得早，所以早期很多语言都提供了对应的客户端。
- **通过 Watcher 机制实现Push模型**：服务机制信息的变更能够及时通知消费者。

缺点：
- **服务规模限制，无法支持超大规模集群**：ZooKeeper 无法支撑太多的 TCP 连接。
- **主从模式下，主节点就是写瓶颈。**（mysql为什么要分库分表，就是写瓶颈）
- **主从模式偶尔还会出现脑裂的问题。**
- **主节点选举的时候，集群不可用。**

从缺点里面也可以看出来，ZooKeeper 是一个 CP 模型。
中小规模集群使用 Zookeeper 作为注册中心，一般不会有什么问题。


##### Eureka
Eureka 采用了对等集群，并且选择了 AP 模型。
**Eureka集群里面有很多节点，节点之间的地位都是平等的，相互之间会进行数据同步。**

理论上来说，客户端不管连上哪一个节点都能获得数据。

所以用它来作为注册中心的优点是：
- **可用性更高，能够支撑住更大规模的集群。**
- **适合横向扩展，避免出现单节点的写入瓶颈**（对比主从模式）。

缺点也有：
- **服务发现比较慢**。这很正常，因为服务注册的时候只会注册到一个节点，要等这个数据扩散到整个集群。
- **多语言支持比较差**。有些语言可能没有客户端，或者有客户端，但是客户端的质量比较差，BUG多。


##### Nacos

Nacos 是一个很有意思的框架，因为它同时支持 CP 和 AP 两种模式。

优点：
- **高可用性**：Nacos 本身有 AP 模式，并且也支持熔断降级等措施，进一步提高可用性。
- **中文社区**：如果你在社区求助，那么基本上不会遇到语言堡垒。
- **功能更加丰富**：例如根据 namespace 命名空间，Group 等来区分不同环境。

缺点：
- 部署和运维的难度要高一些。
- CP 和 AP 集成在一起，源码复杂度高，难以理解。多语言支持比较差：同样的，部分语言的客户端质量很差。

##### 注册中心选型总结
结论：小规模集群随便选，你熟悉哪个用哪个，**大规模集群优先考虑 etcd。**

不过，从理论上来说注册中心选型要考虑：
- 通用标准：成熟度高、社区支持完善。
- 扩展性：如果将来业务增长了，集群规模扩大，注册中心能不能跟着扩展。
- 成本因素：即部署一个集群需要的节点数量。
- 集群：对等集群还是从主从集群，优先考虑对等集群。
- CAP：优先考虑 AP。

ps：现实中选型其实没那么讲究。基本上就是自己写一个文档，罗列一下各种中间件的优缺点，然后自己给个建议。
而后揣摩老板的看法，老板偏向哪个就选哪个。老板不管那就自己按照喜好挑选一个。你可以认为：前面这些成熟的中间件，你挑哪个都不会出问题，但是也都有可能出问题。

