### 负载均衡
服务注册与发现，已经解决了“**有哪些可用服务实例**”的问题，现在就要讨论下一个问题：
**这么多可用服务实例，我该把请求发给谁？**

这一步，我们直觉就想到关键字：负载均衡。

事实上负载均衡是手段而不是目的。因此从目的上来说，我们其实不需要搞什么负载均衡，我们的目的就死活把请求转发给“最合适”处理这个请求的节点。最合适处理意味着：
- 如果这个请求需要很多内存，那么将它转发给内存多的节点。
- 如果这个请求是 CPU 密集的，那么将它转发给 CPU 比较空闲的请求。
- ......

显然，在大多数时候，我们会希望将请求转发给“能够最快返回响应”的那个节点。


### 负载均衡的本质
在这种情况，你应该理解到：负载均衡本质上是一个简化模型。

也就是说，如果我们的目标是挑选出那个最合适的节点，我们就得建设一个标准。

而这个标准，被简化为“负载”。换言之，**我们认为负载最轻的就是最合适的**。

而考虑到所有的节点都提供同等的服务，那么你每次挑选负载最轻的节点，**就造成所有的节点负载是大致均衡的**。



### 负载均衡算法：静态负载均衡算法
因此，你可以进一步总结出来，所谓的负载均衡算法，实际上就是尝试着在所有的节点里，挑选出一个最好的目标节点。

大体上来说，负载均衡有两大类：静态负载均衡算法和动态负载均衡算法。

**静态负载均衡的思路是完全不管节点的实际负载，而是依靠统计学来保证负载是均衡的。**

也就是说，只要发的请求足够多，这些节点就大概率负载是均衡的。

主要有：**轮训、加权轮训、随机、加权随机、哈希、一致性哈希**。

所以，你可以认为静态负载均衡算法就是摆烂，反正都算不出实际的负载，我索性直接不算了。


#### 轮训
轮训算法的效果很不错，而且应该是应用最广泛的负载均衡算法了。

**轮训的思路非常简单，也就是一个个节点的轮流过去。**

虽然轮训的算法很简单（实现也很简单），但是它效果很不错。应该说，绝大多数情况下，直接使用轮训算法不会有任何问题。

但是轮训本身有两个假设：
- 所有服务器的处理能力是一样的。
- 所有请求所需的资源也是一样的。

而在实践中，这两个假设，尤其是第二个假设，并不成立。**因此轮训用多了，难免会遇到偶发性的负载不均衡问题**。

典型例子就是某个节点收到一个大请求，直接把自己打爆了。


#### 加权轮询
加权轮询是对轮询的一个改进。

算法大体上还是轮询，但是不再是一个请求一个节点这样轮询，**而是按照权重来轮询。权重多的多分到几个请求，权重小的就少几个请求。**

权重大多数时候都是代表了服务端节点的处理能力（重要性、优先级等）。

还有一些比较罕见的情况是在多活的场景下，同机房、同城的节点会有更高的权重。

**如何获得权重？**
在注册中心模型下，权重基本上是通过注册中心来传递的。

**也就是每一个服务端节点在启动的时候会把自己的权重信息也注册进去**。
客户端在服务发现的过程中，就能获得对应的权重信息。


**普通加权轮询的权限**
普通加权轮询，有一个缺陷：**权重高的服务端节点会连续收到多个请求**


#### 平滑的加权轮询
加权轮询算法是在加权算法的基础上，引入了一个 currentWeight（当前权重）的概念。每次选中一个节点之后，就降低 currentWeight。

于是一个节点就有两个权重：初始权重和当前权重。整个算法的步骤：
- **计算所有的初始权重的和，也就是总权重。**
- **每一个节点，都让自己的当前权重加上初始权重。**
- **选出当前权重最大的节点，发送请求。**
- **将选出的节点的当前权重减去总权重。**


#### 随机
随机算法比轮询还要简单，就是随表挑一个。

从实现的角度来说，就是生成一个随机数，**利用随机数除以总节点数量，得到的余数就是节点的下标。**

随机算法有两个假设：
- 所有服务器的处理能力是一样的。
- 所有请求所需的资源也是一样的。

并且，随机算法还认为在请求数量足够多的情况下，节点负载是均衡的。

当然，**如果你特别倒霉，也是会遇到负载不均衡的问题。**



#### 加权随机
加权随机类似于加权轮询，给每一个节点一个权重。

加权随机的基本思路：
- **计算一个总权重 T。**
- **生成一个随机数 r。**
- **r 落到总权重的哪个区间，就选择哪个节点。**


加权随机没有平滑的加权随机版本，因为用不上。


#### 哈希
哈希算法核心就是根据业务特征来计算一个哈希值，而后除以节点总数，就是目标节点。

你可以将哈希和随机结合一起看，**那么随机算法就是用随机数，而哈希算法就是用业务特征来计算哈希值。**

所谓的业务特征，可以是：
- 业务 ID
- 外键
- 唯一索引
- ......

跟你的业务是密切相关的。


#### 加权哈希算法
加权哈希算法也类似于加权随机算法。

**用哈希值代替了随机数，就变成了加权哈希算法**


#### 一致性哈希
一致性哈希算法是哈希算法的改进，引入了一个类似环。

同样的计算哈希值，但是哈希值和节点的关系是：**哈希值落在某一个区间内，会被特定的一个节点处理。**

**因此优势就是当增加节点或者减少节点的时候，只有一部分请求命中的节点会发生变化。**



### 动态负载均衡算法
动态负载均衡算法核心在于：尝试实时计算节点的负载。

而在实践中，我们其实也不知道怎么定量计算一个节点的负载，所以动态负载均衡算法也只能根据各自的理解，选择一些指标。

常见的有：
- **最少连接数**
- **最少活跃度**
- **最快响应**


#### 最少连接数
基本的想法就是：**如果一个节点上的负载很高，那么连到这个节点的连接数量肯定很多。**

每次挑选节点的时候，客户端看看自己这边所有的候选节点的连接数有多少，然后**挑选最少连接数的节点。**

但是这里面有缺陷：如果是在连接多路复用的情况下，也就是一个连接可以同时被多个请求复用的时候，那么连接数少的，可能负载反而更高。

比如说服务端 A 上面十个连接，可能被100个请求复用，但是服务端C上面的十二个节点，可能只有50个请求复用。


#### 最少活跃数
活跃数是指正在被处理的请求数量。

很显然，活跃请求数还是比较准确的。

**客户端为每一个服务端节点维持一个活跃请求数计数，每次发请求的时候选择一个活跃数最低的节点。**


#### 最快响应时间
**简而言之：每次挑选曾经最快返回响应的节点。**

这个响应时间可以是：
- 平均响应时间
- 99 线
- 999 线

推荐平均响应时间或者99线


### 负载均衡总结
1. **要不要考虑服务器处理能力？**
- 轮询、随机、哈希、最少连接数、最少活跃数都没考虑
- 对于的加权版本，就可以用权重来代表服务器的处理能力。
2. **选择什么指标来表达服务器当前负载？**
- (加权)轮训、(加权)随机、哈希什么都没选，依赖于统计。
- 选择连接数、请求数、响应时间、错误率......**所以你可以随便选几个指标，然后设计自己的负载均衡算法。**
3. 是不是所有的请求所需的资源都是一样的？显然不是
- 大商家品类极多，大买家订单极多。
- **不考虑请求消耗资源的负载均衡，容易出现偶发性的打爆某一台实例的情况。**
4. 选什么负载均衡算法？**实践中遇事不决用轮训**，出了问题再说。

#### 权重效果
- 大多数时候我们都是**使用权重表达服务器的处理能力**，或者说重要性、优先级。
- 使用权重的算法都要考虑：
- - 某个实例的权重特别大，可能连续几次都会选中他，那么**要考虑平滑效果。**
- - **结合实际调用结果来调整权重**，例如实例如果返回了错误，那么就降低权重，反之就增加权重。
- - 一个实例的权重如果是动态调整的，那么就**要考虑上限和下限的问题**，尤其要考虑调整权重的过程中会不会导致权重变成0、最大值或者最小值。这三个值可能导致实例完全不被选中，或者一直被选中。



#### 微服务框架的局限性
前面我们聊到的三个动态负载均衡算法：最少连接数、最少活跃数、最快响应时间算法都是客户端来选择的。

但是客户端只知道自己这一边的情况，也就是：
- **客户端只知道自己和各个服务端节点的连接数。**
- **客户端只知道自己发过去，还没收到的响应的请求数。**
- **客户端只知道自己发过去的请求的响应时间，**

微服务框架不具备全局信息，两个客户端，自己从自己的视角选择最佳的节点，但是不能从全局的角度选择。

#### 设计自己的负载均衡算法
核心是**根据自己的业务特征来选取一些指标，来表达服务实例的负载。**
- 错误率等其他服务指标。
- CPU、IO、网络负载等硬件指标。

要想知道这些指标，除了客户端统计（有些客户端没法统计，例如每个实例的CPU），还有一些奇技淫巧：
- **服务端将指标的值写入注册中心**，注册中心通知客户端。
- 服务端**每次返回响应的时候，额外带上自己的指标**，如CPU利用率。
- **利用我们的可观测性平台**，从观测性平台获得数据。



### gRPC中默认的负载均衡算法：

grpc在默认情况下，**可以认为是没有负载均衡算法的，因为它永远只会选择第一个节点**。

这个第一个节点是你在 Resolver 里面解析出来的第一个节点。当然大多数时候，第一个节点是什么你一点都不关心，也没啥影响。


### gRPC 中使用 round_robin 算法
gRPC 提供了一些复杂均衡算法的实现，可以直接使用。

比如说**轮训算法，大多数时候你直接使用这个算法就足够了**。

要注意，这里是一个 gRPC 的垃圾设计，即传入 JSON 串。这里很容易写错。

```go
bd, err := resolver.NewBuilder(client)
	if err != nil {
		panic(err)
	}
opts := []grpc.DialOption{grpc.WithResolvers(bd), grpc.WithDefaultServiceConfig(`{"loadBalancingConfig":[{"round_robin":{}}]}`)}
```

round_robin 没有任何配置，所以后面就是一个 {}


### gRPC round_robin 算法实现
gRPC 的 round_robin **算法实现很简单，核心就是利用原子操作来更新候选节点的下表**。

```go
type rrPicker struct {
	// subConns is the snapshot of the roundrobin balancer when this picker was
	// created. The slice is immutable. Each Get() will do a round robin
	// selection from it and return the selected SubConn.
	subConns []balancer.SubConn
	next     uint32
}

func (p *rrPicker) Pick(balancer.PickInfo) (balancer.PickResult, error) {
	subConnsLen := uint32(len(p.subConns))
	nextIndex := atomic.AddUint32(&p.next, 1)

	sc := p.subConns[nextIndex%subConnsLen]
	return balancer.PickResult{SubConn: sc}, nil
}
```


### gRPC 中使用加权负载均衡算法
gRPC 本身就提供了加权负载均衡算法实现。

使用起来有两个地方需要修改：
- **匿名引入基于权重的负载均衡算法**，也就是初始化好这个算法。
- **在客户端启动的时候指定使用加权轮训算法。**

```go
import (
    _ "google.golang.org/grpc/balancer/weightedroundrobin"
)
opts := []grpc.DialOption{
grpc.WithResolvers(bd),
// 使用轮训负载均衡算法
grpc.WithDefaultServiceConfig(`{"loadBalancingConfig":[{"weighted_round_robin": {}}]}`),
}
```

#### 匿名引入的意义
匿名引入就是为了初始化好这个算法。

**也就是触发包中的 init 方法。**

这个在 Go 里面是非常常见的一种设计模式。即提供一个中间的注册方法，而后通过匿名引入来注册某个实现。

后续的所有使用的地方，都根据注册的名字来查找对应的实现。


#### 加权负载均衡算法原理
gRPC 中的加权均衡算法并不是我们之前讨论的服务端配置权重的加权算法。gRPC 是自己主动计算每个节点的权重。它会根据每个节点的 QPS、错误率来计算一个权重。

简单来说，**QPS 越高，权重越大；错误率越高，权重越低**。而后，利用 EDF 算法（Earliest Deadline First）从这些节点里面挑选出来一个。


### gRPC 中支持其他负载均衡算法
gRPC 自带的负载均衡算法你可以在 gRPC 下的子包 balancer 里面找到。
- grpclb：统一控制负载均衡的实现，用来集成其他负载均衡算法实现的，不需要用。
- leastrequest：最少请求数算法，实验特性，不要用。
- rls：集成了限流的负载均衡算法实现，也要配合其他负载均衡算法来使用，实验特性，不要用。
- roundrobin：轮询。
- weightedroundrobin：加权轮训。

总结就是，**除了 roundrobin 其他都没什么使用的必要。**


### 在 gRPC 中接入自己的负载均衡算法
有时候你需要根据业务特征来定制一些负载均衡算法，那么**就需要了解怎么接入自定义的算法**。

在 gRPC 里面，实现一个自定义算法，需要实现两个关键接口：
- PickerBuilder：它在 balancer.base 子包里面。
- Picker：在 balancer 子包下面。

```go
package wrr

import (
	"google.golang.org/grpc/balancer"
	"google.golang.org/grpc/balancer/base"
)

const name = "custom_wrr"

func init() {
	// NewBalancerBuilder 是帮我们把一个 Picker Builder 转化为一个 balancer builder
	balancer.Register(base.NewBalancerBuilder(name, &PickerBuilder{}, base.Config{HealthCheck: true}))
}

//传统版本的基于权重的负载均衡算法

type PickerBuilder struct {
}

func (p *PickerBuilder) Build(info base.PickerBuildInfo) balancer.Picker {
	var conns []*conn
	for sc, scInfo := range info.ReadySCs {
		cc := &conn{
			cc: sc,
		}

		md, ok := scInfo.Address.Metadata.(map[string]any)
		if ok {
			weightVal := md["weight"]
			weight, _ := weightVal.(float64)
			cc.weight = int(weight)
		}

		if cc.weight == 0 {
			cc.weight = 50
		}
		cc.currentWeight = cc.weight
		conns = append(conns, cc)

	}
	return &Picker{
		conns: conns,
	}
}

// Picker 这个才是真的执行负载均衡的地方
type Picker struct {
	conns []*conn
}

// Pick 在这里实现基于权重的负载均衡算法
func (p *Picker) Pick(info balancer.PickInfo) (balancer.PickResult, error) {
	if len(p.conns) == 0 {
		// 没有候选节点
		return balancer.PickResult{}, balancer.ErrNoSubConnAvailable
	}
	var total int
	var maxCC *conn
	// 计算当前权重
	for _, cc := range p.conns {
		total += cc.weight
		cc.currentWeight += cc.weight
		if maxCC == nil || cc.currentWeight > maxCC.currentWeight {
			maxCC = cc
		}
	}
	// 更新
	maxCC.currentWeight -= total
	// maxCC 就是挑出来的
	return balancer.PickResult{
		SubConn: maxCC.cc,
		Done: func(info balancer.DoneInfo) {
			// 很多动态算法，根据通用结果来调整权重，就在这里
		},
	}, nil
}

// conn 代表节点
type conn struct {
	// 权重
	weight        int
	currentWeight int

	// 真正的，grpc 里面的代表一个节点的表达
	cc balancer.SubConn
}

```

#### 自定义基于权重的负载均衡算法
这个算法的要点：
- **要在客户端这边拿到服务端节点的权重。**
- **利用权重实现一个平滑的基于权重的负载均衡算法。**

之前我们提到过，要在服务端到客户端之间传递元数据，那么就要利用到注册时候的 metadata 字段。

大部分时候，**每一个节点的权重信息都是从配置文件或者环境变量里面读取到的。**



### Kratos 中的负载均衡：默认算法

**在默认情况下，Kratos 使用的是平滑的加权轮训算法**。也就是，你不指定使用任何负载均衡算法的时候，用的就是这个。

实际上，在 Kratos 里面，负载均衡被进一步抽象（封装）为了一个 Selector 概念，允许你传入一些 filter 来过滤一些服务端节点。

这个 filter 功能你可以看做是分组/路由的统一抽象。


#### Kratos 中支持的负载均衡算法
- P2C（Pick of 2 Choices）：简单来说就是先随机选出两个节点，这两个节点需要满足一定的条件，而后再从这两个节点里面选出一个负载比较低的节点。
- Random：随机负载均衡算法。
- WRR：平滑肌的加权负载均衡算法。

**正常默认使用 WRR 就可以了。**



### go-zero 中的负载均衡
go-zero的默认负载均衡算法是 p2c。
并且，这个框架内部直接写死的
如果要修改，就必须**传入一个原生的grpc.WithDefaultServiceConfig 覆盖掉**。


### 总结
- 不管是自定义负载均衡算法，还是不同框架接入负载均衡，只要是用的是 gRPC，那么就**绕不开 PickBuilder 和 Picker两个接口。**
- 进一步可以推论，这些框架基本上也是**借助 WithDefaultServiceConfig 来指定负载均衡算法的。**
- 已有的负载均衡实现已经能够解决大多数问题了，除非逼不得已，**已经不需要实现自定义的负载均衡算法了**。




### 在 gRPC 中实现 Failover 机制

#### failover 机制
在第三方调用那里，我们详细说明了如何进行 failover。那里讨论的措施在 grpc 里面也是一样适用的。

failover 讨论的就是：**如果我下游的某一个节点崩溃了，或者说我连不上了，怎么解决**。可能的原因有：
- 下游服务确实崩溃了。
- 和下游节点的网络出现了问题。
- 下游服务下限了，但是客户端还没得到注册中心的通知。

在 gRPC 里面，因为 gRPC 本身的封装已经很完善了，所以做起来比较麻烦。


#### 在 gRPC 中实现 failover 的基本思路

在 gRPC 中实现 failover 的基本思路简单来说就是：重试 + 负载均衡。
- 重试：**当调用不通的时候，gRPC 会重试，再次经过负载均衡。**
- 负载均衡：**要确保在某个节点不可用之后，负载均衡的策略不会再次挑选中它。**

